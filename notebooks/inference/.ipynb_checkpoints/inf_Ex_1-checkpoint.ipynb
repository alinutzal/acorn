{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "#from torch import cuda\n",
    "import acorn.core\n",
    "print(acorn.core.__file__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "import yaml\n",
    "from itertools import chain, product, combinations\n",
    "import torch\n",
    "\n",
    "from time import time as tt\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from acorn.stages.data_reading import AthenaReader\n",
    "from acorn.core.infer_stage import infer\n",
    "from acorn.core.eval_stage import evaluate\n",
    "\n",
    "from acorn.stages.data_reading.models.trackml_utils import *\n",
    "\n",
    "from acorn.stages.data_reading.data_reading_stage import EventReader\n",
    "from acorn.stages.data_reading.models.trackml_reader import TrackMLReader\n",
    "\n",
    "from acorn.stages.graph_construction.models.metric_learning import MetricLearning\n",
    "from acorn.stages.edge_classifier.models.filter import Filter\n",
    "from acorn.stages.edge_classifier import InteractionGNN\n",
    "from acorn.stages.edge_classifier.edge_classifier_stage import EdgeClassifierStage\n",
    "\n",
    "from acorn.stages.graph_construction.utils import handle_weighting\n",
    "from acorn.stages.graph_construction.models.utils import graph_intersection, build_edges\n",
    "from acorn.stages.graph_construction.utils import *\n",
    "from acorn.stages.graph_construction.models.py_module_map import PyModuleMap\n",
    "from acorn.stages.graph_construction.graph_construction_stage import GraphConstructionStage\n",
    "\n",
    "from acorn.utils import handle_hard_node_cuts\n",
    "\n",
    "from acorn.stages.track_building import utils \n",
    "from torch_geometric.utils import to_scipy_sparse_matrix\n",
    "\n",
    "#run = wandb.init(project=model_gnn.hparams[\"project\"], entity='gnnproject')\n",
    "torch.set_float32_matmul_precision('highest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidr = \"../../examples/Example_1/data_reader.yaml\"\n",
    "configMm = \"../../examples/Example_1/module_map_infer.yaml\"\n",
    "configGnn = \"../../examples/Example_1/gnn_infer.yaml\"\n",
    "configGnn_eval = \"../../examples/Example_1/gnn_eval.yaml\"\n",
    "configTbi = \"../../examples/Example_1/track_building_infer.yaml\"\n",
    "configTbe = \"../../examples/Example_1/track_building_eval.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_dir = \"/pscratch/sd/a/alazar/cf/Example_1/gnn/\"\n",
    "gnn_val = os.path.join(gnn_dir, \"valset\")\n",
    "all_events = [event for event in os.listdir(gnn_val) if event.endswith(\".pyg\")]\n",
    "all_events = sorted(all_events)\n",
    "event0 = torch.load(os.path.join(gnn_val, all_events[2]))\n",
    "event1 = torch.load(os.path.join(gnn_val, all_events[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(event0.event_id, event1.event_id)\n",
    "print(event0.edge_index.shape, event1.edge_index.shape)\n",
    "print(event0.scores.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracking_dir = \"/pscratch/sd/a/alazar/cf/Example_1/connected_components\"\n",
    "# tracking_val = os.path.join(tracking_dir, \"valset\")\n",
    "# all_events = os.listdir(tracking_val)\n",
    "# event0 = torch.load(os.path.join(tracking_val, all_events[0]))\n",
    "# event1 = torch.load(os.path.join(tracking_val, all_events[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event0.event_id, event1.event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((event0.scores).sum(), (event1.scores).sum())\n",
    "print((event0.scores > 0.8).sum(), (event1.scores > 0.8).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer(configMm)\n",
    "#infer(configGnn,checkpoint=config_gnn['stage_dir']+'artifacts/best-4l0jlwuh-val_loss=0.085163-epoch=77.ckpt')\n",
    "#infer(configTbi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate(configTbe,None,dataset=\"valset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../examples/Example_1/module_map_infer.yaml\", \"r\") as f:\n",
    "    config_mm = yaml.load(f, Loader=yaml.FullLoader)\n",
    "model_mm = PyModuleMap(config_mm)\n",
    "#model_mm.setup(stage=\"predict\")\n",
    "model_mm.load_module_map()\n",
    "model_mm.load_data(\"/pscratch/sd/a/alazar/cf/Example_1/feature_store/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../examples/Example_1/gnn_train.yaml\", \"r\") as f:\n",
    "    config_gnn = yaml.load(f, Loader=yaml.FullLoader)\n",
    "model_gnn = InteractionGNN(config_gnn)\n",
    "model_gnn.setup('fit')\n",
    "model_gnn = InteractionGNN.load_from_checkpoint(config_gnn['stage_dir']+'artifacts/best-4l0jlwuh-val_loss=0.085163-epoch=77.ckpt', hparams=config_gnn)\n",
    "model_gnn.setup('predict')\n",
    "dataloaders_gnn = model_gnn.predict_dataloader()\n",
    "\n",
    "config_tbe = yaml.safe_load(open(\"../../examples/Example_1/track_building_eval.yaml\", \"r\"))\n",
    "print(config_gnn['stage_dir']+'artifacts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_result_summary(\n",
    "    n_reconstructed_particles,\n",
    "    n_particles,\n",
    "    n_matched_tracks,\n",
    "    n_tracks,\n",
    "    n_dup_reconstructed_particles,\n",
    "    eff,\n",
    "    fake_rate,\n",
    "    dup_rate,\n",
    "):\n",
    "    summary = f\"Number of reconstructed particles: {n_reconstructed_particles}\\n\"\n",
    "    summary += f\"Number of particles: {n_particles}\\n\"\n",
    "    summary += f\"Number of matched tracks: {n_matched_tracks}\\n\"\n",
    "    summary += f\"Number of tracks: {n_tracks}\\n\"\n",
    "    summary += (\n",
    "        \"Number of duplicate reconstructed particles:\"\n",
    "        f\" {n_dup_reconstructed_particles}\\n\"\n",
    "    )\n",
    "    summary += f\"Efficiency: {eff:.3f}\\n\"\n",
    "    summary += f\"Fake rate: {fake_rate:.3f}\\n\"\n",
    "    summary += f\"Duplication rate: {dup_rate:.3f}\\n\"\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def tracking_efficiency(dataset, config): #plot_config,\n",
    "    \"\"\"\n",
    "    Plot the track efficiency vs. pT of the edge.\n",
    "    \"\"\"\n",
    "    all_y_truth, all_pt = [], []\n",
    "    #dataset = getattr(self, config[\"dataset\"])\n",
    "\n",
    "    evaluated_events = []\n",
    "    for event in tqdm(dataset):\n",
    "        evaluated_events.append(\n",
    "            utils.evaluate_labelled_graph(\n",
    "                event,\n",
    "                matching_fraction=config[\"matching_fraction\"],\n",
    "                matching_style=config[\"matching_style\"],\n",
    "                sel_conf=config[\"target_tracks\"],\n",
    "                min_track_length=config[\"min_track_length\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    evaluated_events = pd.concat(evaluated_events)\n",
    "    #print(\"Debug: \", evaluated_events)\n",
    "    particles = evaluated_events[evaluated_events[\"is_reconstructable\"]]\n",
    "    reconstructed_particles = particles[\n",
    "        particles[\"is_reconstructed\"] & particles[\"is_matchable\"]\n",
    "    ]\n",
    "    tracks = evaluated_events[evaluated_events[\"is_matchable\"]]\n",
    "    matched_tracks = tracks[tracks[\"is_matched\"]]\n",
    "\n",
    "    n_particles = len(particles.drop_duplicates(subset=[\"event_id\", \"particle_id\"]))\n",
    "    n_reconstructed_particles = len(\n",
    "        reconstructed_particles.drop_duplicates(subset=[\"event_id\", \"particle_id\"])\n",
    "    )\n",
    "\n",
    "    n_tracks = len(tracks.drop_duplicates(subset=[\"event_id\", \"track_id\"]))\n",
    "    n_matched_tracks = len(\n",
    "        matched_tracks.drop_duplicates(subset=[\"event_id\", \"track_id\"])\n",
    "    )\n",
    "\n",
    "    n_dup_reconstructed_particles = (\n",
    "        len(reconstructed_particles) - n_reconstructed_particles\n",
    "    )\n",
    "\n",
    "    eff = n_reconstructed_particles / n_particles\n",
    "    fake_rate = 1 - (n_matched_tracks / n_tracks)\n",
    "    dup_rate = n_dup_reconstructed_particles / n_reconstructed_particles\n",
    "\n",
    "    result_summary = make_result_summary(\n",
    "        n_reconstructed_particles,\n",
    "        n_particles,\n",
    "        n_matched_tracks,\n",
    "        n_tracks,\n",
    "        n_dup_reconstructed_particles,\n",
    "        eff,\n",
    "        fake_rate,\n",
    "        dup_rate,\n",
    "    )\n",
    "\n",
    "    print(f\"Number of reconstructed particles: {n_reconstructed_particles}\")\n",
    "    print(f\"Number of particles: {n_particles}\")\n",
    "    print(f\"Number of matched tracks: {n_matched_tracks}\")\n",
    "    print(f\"Number of tracks: {n_tracks}\")\n",
    "    print(f\"Number of duplicate reconstructed particles: {n_dup_reconstructed_particles}\")   \n",
    "    print(f\"Efficiency: {eff:.3f}\")\n",
    "    print(f\"Fake rate: {fake_rate:.3f}\")\n",
    "    print(f\"Duplication rate: {dup_rate:.3f}\")\n",
    "\n",
    "    #self.log.info(\"Result Summary :\\n\\n\" + result_summary)\n",
    "\n",
    "    # res_fname = os.path.join(\n",
    "    #     self.hparams[\"stage_dir\"],\n",
    "    #     f\"results_summary_{self.hparams['matching_style']}.txt\",\n",
    "    # )\n",
    "\n",
    "    # with open(res_fname, \"w\") as f:\n",
    "    #     f.write(result_summary)\n",
    "\n",
    "    # First get the list of particles without duplicates\n",
    "    grouped_reco_particles = particles.groupby(\"particle_id\")[\n",
    "        \"is_reconstructed\"\n",
    "    ].any()\n",
    "    # particles[\"is_reconstructed\"] = particles[\"particle_id\"].isin(grouped_reco_particles[grouped_reco_particles].index.values)\n",
    "    particles.loc[\n",
    "        particles[\"particle_id\"].isin(\n",
    "            grouped_reco_particles[grouped_reco_particles].index.values\n",
    "        ),\n",
    "        \"is_reconstructed\",\n",
    "    ] = True\n",
    "    particles = particles.drop_duplicates(subset=[\"particle_id\"])\n",
    "\n",
    "    # Plot the results across pT and eta (if provided in conf file)\n",
    "    #os.makedirs(self.hparams[\"stage_dir\"], exist_ok=True)\n",
    "\n",
    "    # for var, varconf in plot_config[\"variables\"].items():\n",
    "    #     utils.plot_eff(\n",
    "    #         particles,\n",
    "    #         var,\n",
    "    #         varconf,\n",
    "    #         save_path=os.path.join(\n",
    "    #             self.hparams[\"stage_dir\"],\n",
    "    #             f\"track_reconstruction_eff_vs_{var}_{self.hparams['matching_style']}.png\",\n",
    "    #         ),\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(configTbi, 'r') as f:\n",
    "    config_tbi = yaml.full_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "\n",
    "\n",
    "device ='cuda'\n",
    "cur_allocated_mem = {}\n",
    "cur_cached_mem = {}\n",
    "max_allocated_mem = {}\n",
    "max_cached_mem = {}\n",
    "i=0\n",
    "\n",
    "model_mm = model_mm.to(\"cuda\")\n",
    "model_gnn = model_gnn.to(\"cuda\")\n",
    "\n",
    "# cur_allocated_mem[i] = cuda.memory_allocated(i)\n",
    "# cur_cached_mem[i] = cuda.memory_reserved(i)\n",
    "# max_allocated_mem[i] = cuda.max_memory_allocated(i)\n",
    "# max_cached_mem[i] = cuda.max_memory_reserved(i)\n",
    "# min_allocated = min(cur_allocated_mem, key=cur_allocated_mem.get)\n",
    "\n",
    "# print('Current allocated memory:', {f'cuda:{k}': v for k, v in cur_allocated_mem.items()})\n",
    "# print('Current reserved memory:', {f'cuda:{k}': v for k, v in cur_cached_mem.items()})\n",
    "# print('Maximum allocated memory:', {f'cuda:{k}': v for k, v in max_allocated_mem.items()})\n",
    "# print('Maximum reserved memory:', {f'cuda:{k}': v for k, v in max_cached_mem.items()})\n",
    "# print('Suggested GPU:', min_allocated)\n",
    "\n",
    "# from acorn.stages.edge_classifier.edge_classifier_stage import GraphDataset\n",
    "# gnn_dataset = GraphDataset(config_gnn['input_dir'], hparams=config_gnn)\n",
    "# from acorn.stages.track_building.track_building_stage import GraphDataset as TrackBuildingDataset\n",
    "# tbi_dataset = TrackBuildingDataset(config_tbi['input_dir'], hparams=config_tbi)\n",
    "# tbe_dataset = TrackBuildingDataset(config_tbe['input_dir'], hparams=config_tbe)\n",
    "\n",
    "graphs = []\n",
    "for batch_idx, (graph, _, truth) in enumerate(model_mm.valset):\n",
    "#for batch_idx, batch in enumerate(model_gnn.valset):\n",
    "    graph.to('cuda')\n",
    "    #if batch.event_id != '000000123': continue\n",
    "    batch = model_mm.build_graph(graph, truth) \n",
    "    # want bypass saving to disk\n",
    "    # Initiate a graph dataset instance from \n",
    "    print(batch.event_id)\n",
    "    batch = model_gnn.valset.preprocess_event(batch)\n",
    " \n",
    "    with torch.no_grad():\n",
    "        gnn = model_gnn.shared_evaluation(batch,batch_idx)\n",
    "        batch = gnn['batch']\n",
    "\n",
    "    #batch.scores = torch.sigmoid(gnn['output'])\n",
    "\n",
    "    edge_mask = batch.scores > config_tbi['score_cut']\n",
    "\n",
    "    # Get number of nodes\n",
    "    if hasattr(batch, \"num_nodes\"):\n",
    "        num_nodes = batch.num_nodes\n",
    "    elif hasattr(batch, \"x\"):\n",
    "        num_nodes = batch.x.size(0)\n",
    "    elif hasattr(batch, \"x_x\"):\n",
    "        num_nodes = batch.x_x.size(0)\n",
    "    else:\n",
    "        num_nodes = batch.edge_index.max().item() + 1\n",
    "    # Convert to sparse scipy array\n",
    "    sparse_edges = to_scipy_sparse_matrix(\n",
    "        batch.edge_index[:, edge_mask], num_nodes=num_nodes\n",
    "    )\n",
    "    # Run connected components\n",
    "    _, candidate_labels = sps.csgraph.connected_components(\n",
    "        sparse_edges, directed=False, return_labels=True\n",
    "    )\n",
    "    batch.labels = torch.from_numpy(candidate_labels).long()\n",
    "\n",
    "    # tbe_dataset.preprocess_event(batch)\n",
    "\n",
    "    graphs.append(batch.to('cpu'))\n",
    "    del batch, gnn \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "tracking_efficiency(graphs, config_tbe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gnn.valset.preprocess = True\n",
    "for event in model_gnn.valset:\n",
    "    if event.event_id != '000000108': continue\n",
    "    event = event.to('cuda')\n",
    "    # print(event.event_id, event.edge_index.shape, (event.truth_map > -1).sum())\n",
    "    event = model_gnn.valset.preprocess_event(event)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting edges according to first hit_id and then 2 hit_id\n",
    "\n",
    "def sorted_edge_index(edge_index, tensor):\n",
    "    dst = edge_index[1]\n",
    "    sorted_indices = torch.argsort(dst)\n",
    "    edge_index = edge_index[:, sorted_indices]\n",
    "    tensor = tensor[sorted_indices]\n",
    "    outter_sorted_indices = torch.argsort(edge_index[0])\n",
    "    edge_index = edge_index[:, outter_sorted_indices]\n",
    "    tensor = tensor[outter_sorted_indices]\n",
    "    return edge_index, tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_sorted_edge_index, event_scores = sorted_edge_index(event0.edge_index, event0.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_sorted_edge_index, batch_scores = sorted_edge_index(batch.edge_index, batch.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_scores, batch_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = sns.histplot(event0.scores.cpu().numpy(), bins=100, log_scale=(False, True))\n",
    "sns.histplot(scores.cpu().numpy(), ax=ax, bins=100, log_scale=(False, True), alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event0.to('cuda').scores.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_sorted_edge_index = sorted_edge_index(event0.edge_index.cpu())\n",
    "batch_sorted_edge_index = sorted_edge_index(batch.edge_index.cpu())\n",
    "(event_sorted_edge_index - batch_sorted_edge_index).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event0.weights.sum(), batch.weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sorted_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = (event_sorted_edge_index - batch_sorted_edge_index).abs()\n",
    "difference = difference[0] + difference[1]\n",
    "mask = difference > 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_sorted_edge_index[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_sorted_edge_index[:, mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event0.scores.max(), event0.scores.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.scores.max(), batch.scores.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, event0.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def concatenate_unicode_strings(a, b):\n",
    "    return a + b\n",
    "\n",
    "string1 = \"Hello\"\n",
    "string2 = \"World\"\n",
    "result = concatenate_unicode_strings(string1, string2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import dask_cudf\n",
    "    import cudf\n",
    "    s = cudf.Series(['detamax_'])\n",
    "    s= s.str.cat(['12'])\n",
    "    print(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext cudf.pandas\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import cudf\n",
    "myids=np.random.choice(np.arange(10000000), size=10000000, replace=False)\n",
    "df1 = pd.DataFrame(myids, columns=['A'])\n",
    "df1['B'] = np.random.randint(0,1000,(10000000))\n",
    "df2 = pd.DataFrame(np.random.permutation(myids), columns=['A2'])\n",
    "df2['B2'] = np.random.randint(0,1000,(10000000))\n",
    "\n",
    "ddf1 = cudf.from_pandas(df1)\n",
    "ddf2 = cudf.from_pandas(df2)\n",
    "ddf1.set_index(\"A\", inplace=True)\n",
    "ddf2.set_index(\"A2\", inplace=True)\n",
    "\n",
    "pdf1 = pl.from_pandas(df1)\n",
    "pdf2 = pl.from_pandas(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "    x = ddf1.merge(ddf2, how='inner', left_on='A', right_on='A2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "    x = ddf1.join(ddf2, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "    x = df1.merge(df2, how='left', left_on='A', right_on='A2')   \n",
    "#1 loop, best of 3: 664 ms per loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit  \n",
    "    x = df1.set_index('A').join(df2.set_index('A2'), how='left') \n",
    "#1 loop, best of 3: 354 ms per loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "    df1.set_index('A', inplace=True)\n",
    "    df2.set_index('A2', inplace=True)\n",
    "#Wall time: 16 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "    x = df1.join(df2, how='left')  \n",
    "#10 loops, best of 3: 80.4 ms per loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "    x = pdf1.join(pdf2, how='left',left_on=\"A\", right_on=\"A2\")  \n",
    "#10 loops, best of 3: 80.4 ms per loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "\n",
    "df = cudf.DataFrame({\n",
    "    'a': [1,2,3],\n",
    "    'b': [4,5,6]\n",
    "})\n",
    "\n",
    "def f(row):\n",
    "    x = row['a']\n",
    "    y = row['b']\n",
    "\n",
    "    return x + y - 1\n",
    "\n",
    "result = df.apply(f, axis=1)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
